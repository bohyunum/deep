{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting c:/tmp/mnistdata\\train-images-idx3-ubyte.gz\n",
      "Extracting c:/tmp/mnistdata\\train-labels-idx1-ubyte.gz\n",
      "Extracting c:/tmp/mnistdata\\t10k-images-idx3-ubyte.gz\n",
      "Extracting c:/tmp/mnistdata\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#MNIST 다운로드\n",
    "mnist      = input_data.read_data_sets('c:/tmp/mnistdata', one_hot=True) #숫자 하나만 선택되도록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "input_size=784\n",
    "layer1_size = 1024\n",
    "layer2_size = 1024\n",
    "output_size = 10\n",
    "learning_rate = 0.01\n",
    "training_epochs = 30\n",
    "batch_size = 100\n",
    "regularization_rate = 0.001\n",
    "\n",
    "# tf Graph Input\n",
    "x_input = tf.placeholder(tf.float32, [None, input_size]) # MNIST 이미지 사이즈 28*28=784\n",
    "y_label = tf.placeholder(tf.float32, [None, output_size]) # 0-9 범위안의 답 => 10 classes\n",
    "\n",
    "with tf.variable_scope('scope' + str(random.random())): #get_variable 재실행 시 오류 회피\n",
    "    # Weight 초기화 \n",
    "    W1 = tf.get_variable('W1',shape=[input_size, layer1_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b1 = tf.Variable(tf.zeros([layer1_size]))\n",
    "    W2 = tf.get_variable('W2',shape=[layer1_size, layer2_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b2 = tf.Variable(tf.zeros([layer2_size]))\n",
    "    W3 = tf.get_variable('W3',shape=[layer2_size, output_size],initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b3 = tf.Variable(tf.zeros([output_size]))\n",
    "\n",
    "# Model 정의\n",
    "layer1 = tf.add(tf.matmul(x_input, W1), b1)\n",
    "layer1 = tf.nn.relu(layer1)\n",
    "\n",
    "layer2 = tf.add(tf.matmul(layer1, W2), b2)\n",
    "layer2 = tf.nn.relu(layer2)\n",
    "\n",
    "y_predict = tf.add(tf.matmul(layer2, W3), b3) #분류를 위해 Softmax가 필요하나, 아래 cost함수에서 함께해 줌\n",
    "\n",
    "# Error Cost 계산\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels= y_label, logits= y_predict))\n",
    "\n",
    "#Weight Decay 적용\n",
    "regularizers = tf.nn.l2_loss(W1)  + tf.nn.l2_loss(W2) + tf.nn.l2_loss(W3)\n",
    "cost = tf.reduce_mean(cost + (regularization_rate * regularizers))\n",
    "\n",
    "# Optimizer \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy 계산\n",
    "correct_prediction = tf.equal(tf.argmax(y_predict, 1), tf.argmax(y_label, 1)) #prediction과 label이 같은지 비교\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.700856532 정확도: 0.950200021\n",
      "Epoch: 0002 cost= 0.362616135 정확도: 0.948199987\n",
      "Epoch: 0003 cost= 0.331577717 정확도: 0.948800027\n",
      "Epoch: 0004 cost= 0.333035955 정확도: 0.952000022\n",
      "Epoch: 0005 cost= 0.313106403 정확도: 0.934300005\n",
      "Epoch: 0006 cost= 0.307151487 정확도: 0.945599973\n",
      "Epoch: 0007 cost= 0.306624084 정확도: 0.955600023\n",
      "Epoch: 0008 cost= 0.301215586 정확도: 0.956799984\n",
      "Epoch: 0009 cost= 0.300426492 정확도: 0.950800002\n",
      "Epoch: 0010 cost= 0.299093987 정확도: 0.945200026\n",
      "Epoch: 0011 cost= 0.297677599 정확도: 0.943799973\n",
      "Epoch: 0012 cost= 0.295038388 정확도: 0.950399995\n",
      "Epoch: 0013 cost= 0.291845517 정확도: 0.956499994\n",
      "Epoch: 0014 cost= 0.293591038 정확도: 0.950999975\n",
      "Epoch: 0015 cost= 0.288294579 정확도: 0.953199983\n",
      "Epoch: 0016 cost= 0.287471419 정확도: 0.959900022\n",
      "Epoch: 0017 cost= 0.285176849 정확도: 0.955399990\n",
      "Epoch: 0018 cost= 0.288693353 정확도: 0.944400012\n",
      "Epoch: 0019 cost= 0.285301744 정확도: 0.950600028\n",
      "Epoch: 0020 cost= 0.284275870 정확도: 0.955799997\n",
      "Epoch: 0021 cost= 0.287533305 정확도: 0.951799989\n",
      "Epoch: 0022 cost= 0.284389989 정확도: 0.958500028\n",
      "Epoch: 0023 cost= 0.286163570 정확도: 0.953800023\n",
      "Epoch: 0024 cost= 0.284945749 정확도: 0.954400003\n",
      "Epoch: 0025 cost= 0.279661023 정확도: 0.956900001\n",
      "Epoch: 0026 cost= 0.279500921 정확도: 0.954699993\n",
      "Epoch: 0027 cost= 0.284836061 정확도: 0.947899997\n",
      "Epoch: 0028 cost= 0.279632949 정확도: 0.950999975\n",
      "Epoch: 0029 cost= 0.286661420 정확도: 0.956399977\n",
      "Epoch: 0030 cost= 0.281119412 정확도: 0.957799971\n",
      "학습 끝!\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training 사이클\n",
    "    for epoch in range(training_epochs): #반복횟수\n",
    "        avg_cost = 0. #평균 Cost 변수\n",
    "        \n",
    "        total_batch = int(mnist.train.num_examples / batch_size) #Loop를 도는 횟수 계산\n",
    "        \n",
    "        # Loop 실행\n",
    "        for i in range(total_batch):\n",
    "            \n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)  #mnist.train.next_batch 함수로 batch_size만큼 한번에 꺼냄\n",
    "            \n",
    "            # Fit training using batch data\n",
    "            _, _cost = sess.run([optimizer, cost]\n",
    "                                         , feed_dict={x_input: batch_xs, y_label: batch_ys})\n",
    "            \n",
    "            # 평균 Cost 계산\n",
    "            avg_cost += _cost / total_batch\n",
    "        acc = sess.run(accuracy, feed_dict={x_input: mnist.test.images, y_label: mnist.test.labels})\n",
    "        print (\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost), \"정확도:\", \"{:.9f}\".format(acc)) #진행상황 출력\n",
    "        \n",
    "    print(\"학습 끝!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
